# SmartMonitor TFM: Detecci√≥n de Fallos Industriales mediante Clustering, Modelado Predictivo y Dashboard Streamlit

![SmartMonitor](assets/icono_smartmonitor.png)

---

## Descripci√≥n del Proyecto

El proyecto SmartMonitor TFM se centra en anticipar fallos cr√≠ticos en sistemas industriales complejos, un reto esencial dado el elevado coste que implica una parada no planificada. Aprovechando una colecci√≥n de experimentos ‚Äúrun-to-failure‚Äù ‚Äìcon alta variabilidad, presencia de outliers y cambios abruptos‚Äì se ha dise√±ado un pipeline de preprocesamiento y modelado predictivo. Adem√°s, se ha desarrollado un dashboard en Streamlit para visualizar datos y cluster.

---

## Contenido del Repositorio

| Carpeta               | Funci√≥n                                                                              |
|-----------------------|--------------------------------------------------------------------------------------|
| **app/**              | Dashboard en Streamlit (`app.py`) con visualizaci√≥n de KPIs y cl√∫steres.               |
| **src/smartmonitor/** | C√≥digo reutilizable: preprocesamiento, validaci√≥n y script de entrenamiento (`Complete_Project.py`). |
| **data/**             | Muestra reducida del CSV original (`date_production.zip`).                           |
| **assets/**           | Gr√°ficos e im√°genes que respaldan el an√°lisis y el README.                           |
| **models/**           | Modelos serializados (Pickles) generados al entrenar (p.ej. `preprocessing_pipeline.pkl`). |

---

## 1. Introducci√≥n: El Reto de Anticipar Fallos

El origen de este trabajo est√° en la necesidad de anticipar fallos cr√≠ticos en sistemas industriales complejos, donde el coste de una parada es muy elevado y la disrupci√≥n puede afectar a toda la cadena de valor. Frente a este reto, contamos con una colecci√≥n de experimentos ‚Äúrun-to-failure‚Äù, cargados de variabilidad, outliers y cambios abruptos. 

---

## 2. Contexto del Proyecto

Para comprender el alcance de este TFM es esencial conocer el entorno en el que opera el sistema.  
**Resumen del Contexto:**  
- **Planta de Producci√≥n:** El proyecto se basa en datos recogidos de una planta de ensamblaje de dispositivos electr√≥nicos y electromec√°nicos, donde la precisi√≥n en la operaci√≥n es vital para sectores cr√≠ticos como el m√©dico y el de telecomunicaciones.  
- **Sensores Cr√≠ticos:** Una red de 25 sensores distribuidos en 8 componentes monitoriza par√°metros esenciales (temperatura, vibraci√≥n, presi√≥n, etc.), capturando informaci√≥n tanto en condiciones √≥ptimas como en estados previos al fallo.  
- **Ensayos Run-to-Failure:** Se han registrado m√∫ltiples experimentos en los que se observa la evoluci√≥n completa hasta la falla final, lo que permite dise√±ar modelos predictivos robustos focalizados en anticipar eventuales incidencias.  
- **Motivaci√≥n:** Al conocer en detalle las fases de deterioro, se busca minimizar paradas no planificadas y optimizar la eficiencia de la l√≠nea de producci√≥n.

_Ejemplos visuales:_

![Sistema_de_monitorizacion_digital](assets/Sistema_de_monitorizacion_digital.png)

![Diagrama_distribucion_registros_por_experimento](assets/Diagrama_distribucion_registros_por_experimento.png)

![Muestra_del_dataset](assets/Muestra_del_dataset.png)

---

No basta con aplicar t√©cnicas est√°ndar: es imprescindible dise√±ar un pipeline que preserve la informaci√≥n relevante, resista el ruido y sea interpretativo. As√≠ comienza este recorrido.

![Diagrama conceptual de Pipeline](assets/Diagrama_conceptual_de_Pipeline.png)

---

## 3. De la exploraci√≥n a la comprensi√≥n: por qu√© cada experimento importa

Desde el principio, el an√°lisis exploratorio muestra que cada experimento es un mundo, con su propio ritmo y din√°mica. Unificar los datos y asignar un `experiment_ID` no es solo una cuesti√≥n de orden, sino la clave para poder comparar, modelar y extraer patrones comunes sin perder la identidad de cada caso. La limpieza de nulos se aborda con pragmatismo: si son pocos, se eliminan; si se espera que en producci√≥n sean m√°s frecuentes, la imputaci√≥n por mediana se convierte en la mejor aliada frente a los extremos y la asimetr√≠a. Contribuir en enriquece el dataset con features que adem√°s favorezcan a mantener la din√°mica y el ritmo siempre mejorar√° el entrenamiento del modelo. Y de ah√≠ la importancia de realizar una conversi√≥n a tipo categ√≥rico de la columna de tiempos `TimeStamp` y el procesamiento a datetime, para calcular el tiempo relativo de queda registro y extraer features temporales.

![Histograma componente Electr√≥nica de Control](assets/Histograma_de_par√°metros_para_el_componente_Electr√≥nica_de_Control.png)

![Histograma componente Motor Paso a Paso](assets/Histograma_de_par√°metros_para_el_componente_Motor_Paso_a_Paso.png)
---

## 3. Los outliers: se√±ales, no ruido

A medida que se visualizan las se√±ales de los sensores, queda claro que los outliers abundan. Sin embargo, lejos de tratarse como errores a eliminar, el an√°lisis revela que muchos de estos valores extremos coinciden con fases cr√≠ticas o inestabilidades previas al fallo. Por eso, la estrategia es conservarlos y tratarlos con m√©todos robustos: el Modified Z-score con MAD sustituye a los cl√°sicos IQR o z-score, porque capta mejor la esencia de la variabilidad industrial y protege la informaci√≥n crucial.

![Gr√°fico boxplot de outliers](assets/Muestra_boxplot_outliers.png)

![Gr√°fico de densidad de los Modified Z-scores](assets/gr√°fico_de_densidad_de_los_Modified_Z-scores.png)

![Dataset enriquecido con features _modified_z y _outliers ](assets/Registros_features__modified_z.png)

---

## 5. Visualizaciones: descubrir relaciones y anticipar el fallo

No basta con mirar medias y desviaciones. La riqueza de los datos se revela en las distribuciones completas, en las colas largas y en la correlaci√≥n ‚Äîo falta de ella‚Äî entre sensores. 
![Gr√°fico de densidad por componente y experimento](assets/Gr√°ficos_de_densidad.png)

---

Los heatmaps y scatter plots permiten intuir redundancias, dependencias y tambi√©n rupturas: cuando el sistema se acerca al fallo, las relaciones se vuelven ca√≥ticas. De ah√≠ que, en las primeras fases, se conserve todo, para no perder pistas potenciales sobre el deterioro.

![Heatmap](assets/Diagrama_de_calor.png)

---

Una vez completado el preprocesamiento y el an√°lisis exploratorio, el siguiente paso consiste en identificar patrones de comportamiento en los datos que permitan anticipar el fallo. Para ello, se recurre a t√©cnicas de clustering no supervisado, siendo K-means uno de los m√©todos m√°s extendidos por su sencillez e interpretabilidad. Sin embargo, la correcta aplicaci√≥n de K-means exige determinar previamente el n√∫mero √≥ptimo de clusters (K) que mejor representa la estructura real de los datos. Para tomar esta decisi√≥n de forma objetiva, se emplean herramientas como el m√©todo del codo y m√©tricas internas de validaci√≥n, cuyos resultados se presentan a continuaci√≥n

![Curva del m√©todo del codo](assets/M√©todo_del_codo.png)

![M√©tricas K-means variando K](assets/Metricas_K-means_variando_K.png)

---

Aunque en este proyecto no se persigue la reducci√≥n de la dimensionalidad ni la eliminaci√≥n de variables, se ha empleado el An√°lisis de Componentes Principales (PCA) con el objetivo de visualizar la estructura interna de los datos en dos dimensiones. Esta t√©cnica facilita la interpretaci√≥n visual, permitiendo observar si existen agrupaciones naturales que respalden la aplicaci√≥n de m√©todos de clustering y la elecci√≥n del n√∫mero √≥ptimo de clusters. De este modo, el uso de PCA se justifica como una herramienta complementaria de exploraci√≥n y validaci√≥n visual, sin afectar a la integridad del conjunto de variables originales utilizado en el modelado.

![ Scatter plot (con reducci√≥n dimensional mediante PCA)](assets/Grafico_de_dispersion_agrupamiento_cluster_K=3_reduccion_PCA.png)

---

## 6. Hacia la objetividad: interpretabilidad y selecci√≥n de variables

La interpretaci√≥n visual es un primer paso, pero no puede ser el √∫nico. Surgen t√©cnicas objetivas como el RandomForestRegressor, Permutation Importance y SHAP, que no solo confirman la intuici√≥n previa (los sensores ‚Äúmodificados‚Äù son cr√≠ticos), sino que cuantifican el peso de cada variable en la predicci√≥n del deterioro temporal. El muestreo estratificado por fases garantiza que esta interpretaci√≥n no se base solo en un periodo, sino en toda la evoluci√≥n de los experimentos.

![ Gr√°fico de Permutation Importance](assets/Diagrama_permutation_importance.png)

![ Gr√°fico Shap](assets/Grafico_Shap.png)

---

## 7. Del clustering cl√°sico al ensemble: robustez frente a la complejidad

La elecci√≥n de K-Means++ no es casual: su estabilidad frente a la inicializaci√≥n y su reproducibilidad lo hacen preferible al azar de K-means tradicional. Sin embargo, los datos industriales desaf√≠an la simplicidad: clusters de densidad variable y cambios abruptos exigen m√©todos como OPTICS, m√°s flexibles y menos dependientes del tuning exhaustivo. La combinaci√≥n de K-Means++, OPTICS y GMM en un ensemble clustering permite capturar tanto los patrones persistentes como las transiciones cr√≠ticas, consolidando finalmente tres estados operativos fundamentales.

---

## 8. Preprocesamiento robusto: cuando la mediana supera a la media

La comparaci√≥n entre StandardScaler y RobustScaler es reveladora. Aunque StandardScaler facilita visualizaciones m√°s limpias, es la mediana ‚Äîmenos sensible a los outliers‚Äî la que realmente refleja la estructura interna de los datos, como lo demuestran las m√©tricas de cohesi√≥n y separaci√≥n de clusters. En un entorno donde los extremos pueden ser la se√±al de un fallo inminente, RobustScaler resulta indispensable para que el modelo no pierda el norte.

---
![Scatterplot y m√©tricas utilizando StandardScaler](assets/Grafico_dispersion_cluster_-_StandardScaler.png)

![Scatterplot y m√©tricas utilizando RobustScaler](assets/Grafico_dispersion_cluster_-_RobustScaler.png)

---

## 9. Validaci√≥n y producci√≥n: de la teor√≠a a la pr√°ctica

Para asegurar que las conclusiones no son fruto del azar ni de la contaminaci√≥n entre experimentos, la validaci√≥n cruzada agrupada (GroupKFold) se convierte en el est√°ndar. Y, pensando en el despliegue real, se entrena un modelo auxiliar RandomForestClassifier sobre los clusters del ensemble, logrando precisi√≥n y rapidez en la asignaci√≥n de etiquetas con una arquitectura ligera, ideal para producci√≥n.

![M√©tricas para Validaci√≥n Cruzada Agrupada(I)](assets/Metricas_validacion_cruzada_agrupada_modelo_auxilar_Fold1-2-3.png)
![M√©tricas para Validaci√≥n Cruzada Agrupada(II)](assets/Metricas_validacion_cruzada_agrupada_modelo_auxilar_Fold4-5_promedio.png)

---

## 10. Conclusiones y recomendaciones: un pipeline guiado por la experiencia

Cada decisi√≥n ‚Äîdesde la gesti√≥n de outliers hasta la validaci√≥n cruzada y la selecci√≥n de escalado‚Äî responde a una necesidad detectada en el an√°lisis de los datos reales. El resultado es un pipeline robusto, interpretable y listo para anticipar fallos en un entorno industrial exigente. Para su uso en producci√≥n, es esencial que el cliente proporcione batches con un √∫nico `experiment_ID` y reinicie el Timestamp tras cada ciclo de fallo, asegurando la trazabilidad y la correcta interpretaci√≥n temporal.

---

## 11. Cierre

Este TFM no solo ha resuelto un problema t√©cnico; ha construido una l√≥gica de trabajo donde cada paso est√° fundamentado en la realidad de los datos y las necesidades de la industria. El porqu√© gu√≠a el c√≥mo, y el resultado es un sistema preparado para la complejidad y el cambio.

---

## 12. Arranque Expr√©s y Ejecuci√≥n del Dashboard

Para probar el proyecto en tu equipo, sigue estos pasos:

```bash
git clone https://github.com/furtu-71/SmartMonitor_ML.git
cd SmartMonitor_ML

# Python ‚â• 3.10 recomendado
python -m venv venv
# Activa el entorno virtual:
# Windows: .\venv\Scripts\activate
# Linux/macOS: source venv/bin/activate
pip install -r requirements.txt

# lanza el dashboard
python -m streamlit run app/app.py
```

Se abrir√° en **http://localhost:8501** y podr√°s explorar tendencias, cl√∫steres y anomal√≠as.

---

## 13. Bibliograf√≠a y Fuentes de Consulta

- **Kaggle - Production Plant Data for Condition Monitoring:**  
  [https://www.kaggle.com/datasets/inIT-OWL/production-plant-data-for-condition-monitoring](https://www.kaggle.com/datasets/inIT-OWL/production-plant-data-for-condition-monitoring)
---
## 14. ¬øC√≥mo funciona el pipeline?

| Paso                    | Archivo / funci√≥n                            | Descripci√≥n breve |
|-------------------------|---------------------------------------------|-------------------|
| Pre-procesado           | `src/smartmonitor/preprocessing_steps.py`   | Validaci√≥n de columnas, categ√≥ricas, ingenier√≠a temporal, duplicados, Modified Z-score, imputaci√≥n mediana, escalado robusto. |
| Muestreo 10 % estrat.   | `sample_experiment_phases()`                | Equilibrio temporal (20-30-50 %). |
| Clustering base         | `Paso 5.3` de `Complete_Project.py`         | Entrena K-Means, OPTICS y GMM sobre 25 columnas *_modified_z_. |
| Ensamblado de cl√∫steres | `Paso 5.4`                                  | Matriz de co-asociaci√≥n ‚Üí Agglomerative (average linkage). |
| Modelo auxiliar         | `Paso 5.5`                                  | Random Forest predice el cl√∫ster ensemble en tiempo real. |

---

## 15. Reentrenar todo desde cero

```bash
python src/smartmonitor/Complete_Project.py
```

Genera de nuevo el pipeline y los modelos en **models/**  
(tiempo ‚âà 12-15 min en un port√°til reciente).

---

## 16. Soluci√≥n de problemas

| S√≠ntoma / mensaje                             | Arreglo r√°pido |
|----------------------------------------------|----------------|
| `ModuleNotFoundError: preprocessing_steps`   | Ejecuta la app desde la ra√≠z (`streamlit run app/app.py`). |
| Falta de RAM en la co-asociaci√≥n             | Baja la fracci√≥n de muestra al 5 % o usa ‚â• 16 GB. |
| Dashboard arranca lento                      | Usa `@st.cache_resource` o comenta modelos que no necesites. |

---

## 17. Contribuir

1. Haz *fork*, crea tu rama (`git checkout -b mejora-x`).  
2. Formatea con `black .` y aseg√∫rate de que los tests (pr√≥ximamente) pasan.  
3. Abre un Pull Request describiendo la mejora y las pruebas.

---

---

## 18 . Licencia y autor√≠a

Proyecto bajo licencia MIT.  
Creado con üõ†Ô∏è y ‚òï por **Fernando Urtubia**  
([@furtu-71](https://github.com/furtu-71)).

> Los datos industriales pueden ser ca√≥ticos; el c√≥digo, no.
